{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe89342-79a8-4683-bd44-658dcfd44c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9267df93-3f11-4aa7-91d8-8fb2cbc38c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff4f842-e511-4fc6-b3f7-52ce6def2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyAFhCDW2CWeUHLr2n7ppdOVqQeRT4YtTHM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2590cf19-71fc-4489-918c-364f4bed982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UCJQJAI7IjbLcpsjWdSzYz0Q'\n",
    "               #more channels here\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f931620-1fa2-498b-bcfd-e03fb2bbdd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "#I will use developer key instead of doing user authentication\n",
    "#client_secrets_file = \"YOUR_CLIENT_SECRET_FILE.json\"\n",
    "# Get credentials and create an API client\n",
    "# flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "#     client_secrets_file, scopes)\n",
    "# credentials = flow.run_console()\n",
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c1cc19-d240-4ac1-8b48-ef832ebba0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube,channel_ids):\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "    #JSON(response)\n",
    "    all_data=[]\n",
    "    for item in response['items']:\n",
    "        data = {'channelName': item['snippet']['title'],\n",
    "                'subscribers': item['statistics']['subscriberCount'],\n",
    "                'views': item['statistics']['viewCount'],\n",
    "                'totalViews': item['statistics']['videoCount'],\n",
    "                'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "               }\n",
    "    all_data.append(data)\n",
    "    return(pd.DataFrame(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53f710b-ead5-4b9e-8d28-0eae1413e0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelName</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>playlistId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>117000</td>\n",
       "      <td>3047946</td>\n",
       "      <td>56</td>\n",
       "      <td>UUJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             channelName subscribers    views totalViews  \\\n",
       "0  Thu Vu data analytics      117000  3047946         56   \n",
       "\n",
       "                 playlistId  \n",
       "0  UUJQJAI7IjbLcpsjWdSzYz0Q  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_statics = get_channel_stats(youtube,channel_ids)\n",
    "channel_statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7461cf-6d2f-4247-a96f-585481974950",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = 'UUJQJAI7IjbLcpsjWdSzYz0Q'\n",
    "def get_video_ids(youtube,playlist_id):\n",
    "    video_ids=[]\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        playlistId=\"UUJQJAI7IjbLcpsjWdSzYz0Q\",\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "    #JSON(response)\n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            playlistId=\"UUJQJAI7IjbLcpsjWdSzYz0Q\",\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        #JSON(response)\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ac14b9-8dd9-4f00-a3c3-fdbb01a54602",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids=get_video_ids(youtube,playlist_id)\n",
    "#len(video_ids)\n",
    "#video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa6b47-13c2-48d1-bb59-3958413b3353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c9f2d1-fd2f-4c52-aca5-c19014852861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube,video_ids):\n",
    "    all_video_info = []\n",
    "    for i in range(0,len(video_ids),50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id =','.join(video_ids[i:i+50])\n",
    "           \n",
    "        )\n",
    "       \n",
    "        response = request.execute()\n",
    "        #JSON(response)\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet':['channelTitle','title','description','tags','publishedAt'],\n",
    "                             'statistics':['viewCount','likeCount','favoriteCount','commentCount'],\n",
    "                             'contentDetails':['duration','definition','caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id'] \n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v]=video[k][v]\n",
    "                    except:\n",
    "                        video_info[v]=None\n",
    "            all_video_info.append(video_info)\n",
    "    return pd.DataFrame(all_video_info)              \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0fce0f-4bac-4e13-bba8-69e786a0b302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tpGawyNMRLM</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>My Entire Process for Doing Data Science Proje...</td>\n",
       "      <td>üß≠ Start planning for your new year with Notion...</td>\n",
       "      <td>[data analytics, data science, python, data, t...</td>\n",
       "      <td>2023-01-23T08:24:17Z</td>\n",
       "      <td>19587</td>\n",
       "      <td>993</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>PT22M45S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_8EV4tdJY2M</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>How to ACTUALLY Achieve Your Data Science Goal...</td>\n",
       "      <td>üõ£ Notion template for building a goal-action s...</td>\n",
       "      <td>[data analytics, data science, python, data, t...</td>\n",
       "      <td>2022-12-30T00:52:40Z</td>\n",
       "      <td>18306</td>\n",
       "      <td>735</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>PT16M13S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QnGotm29cZE</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>Full Stack Data Science Roadmap 2023</td>\n",
       "      <td>üëâ Try Datalore for free: https://jb.gg/datalor...</td>\n",
       "      <td>[data analytics, data science, python, data, t...</td>\n",
       "      <td>2022-12-22T00:49:38Z</td>\n",
       "      <td>108128</td>\n",
       "      <td>4276</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>PT16M30S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZfN8nG0luig</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>RECESSION 2023: Should You Worry About Data Sc...</td>\n",
       "      <td>ü§ì Join my Discord server: \\nhttps://discord.gg...</td>\n",
       "      <td>[data analytics, data science, python, data, t...</td>\n",
       "      <td>2022-12-05T23:40:57Z</td>\n",
       "      <td>39197</td>\n",
       "      <td>1645</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>PT16M25S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GM8nrVBFdFo</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>DON'T DO THIS: Revealing biggest mistakes in d...</td>\n",
       "      <td>üß© Data visualization catalogue üëâ https://datav...</td>\n",
       "      <td>[data analytics, data science, python, data, t...</td>\n",
       "      <td>2022-11-25T10:52:29Z</td>\n",
       "      <td>25877</td>\n",
       "      <td>1364</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>PT14M19S</td>\n",
       "      <td>hd</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id           channelTitle  \\\n",
       "0  tpGawyNMRLM  Thu Vu data analytics   \n",
       "1  _8EV4tdJY2M  Thu Vu data analytics   \n",
       "2  QnGotm29cZE  Thu Vu data analytics   \n",
       "3  ZfN8nG0luig  Thu Vu data analytics   \n",
       "4  GM8nrVBFdFo  Thu Vu data analytics   \n",
       "\n",
       "                                               title  \\\n",
       "0  My Entire Process for Doing Data Science Proje...   \n",
       "1  How to ACTUALLY Achieve Your Data Science Goal...   \n",
       "2               Full Stack Data Science Roadmap 2023   \n",
       "3  RECESSION 2023: Should You Worry About Data Sc...   \n",
       "4  DON'T DO THIS: Revealing biggest mistakes in d...   \n",
       "\n",
       "                                         description  \\\n",
       "0  üß≠ Start planning for your new year with Notion...   \n",
       "1  üõ£ Notion template for building a goal-action s...   \n",
       "2  üëâ Try Datalore for free: https://jb.gg/datalor...   \n",
       "3  ü§ì Join my Discord server: \\nhttps://discord.gg...   \n",
       "4  üß© Data visualization catalogue üëâ https://datav...   \n",
       "\n",
       "                                                tags           publishedAt  \\\n",
       "0  [data analytics, data science, python, data, t...  2023-01-23T08:24:17Z   \n",
       "1  [data analytics, data science, python, data, t...  2022-12-30T00:52:40Z   \n",
       "2  [data analytics, data science, python, data, t...  2022-12-22T00:49:38Z   \n",
       "3  [data analytics, data science, python, data, t...  2022-12-05T23:40:57Z   \n",
       "4  [data analytics, data science, python, data, t...  2022-11-25T10:52:29Z   \n",
       "\n",
       "  viewCount likeCount favoriteCount commentCount  duration definition caption  \n",
       "0     19587       993             0           74  PT22M45S         hd   false  \n",
       "1     18306       735             0           41  PT16M13S         hd   false  \n",
       "2    108128      4276             0          141  PT16M30S         hd   false  \n",
       "3     39197      1645             0           91  PT16M25S         hd   false  \n",
       "4     25877      1364             0           88  PT14M19S         hd    true  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vedio_df = get_video_details(youtube,video_ids)\n",
    "vedio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ff1c1-f9e8-4514-b884-8ae82dc4ff91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68006e19-bc7b-41ff-94bb-0731e2752524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_in_videos(youtube,video_ids):\n",
    "    all_comments=[]\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.commentThreads().list(\n",
    "                  part=\"snippet,replies\",\n",
    "                  videoId=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments_in_video=[comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items']]\n",
    "        comments_in_video_info = {'video':video_id,'comments':comments_in_video}\n",
    "        all_comments.append(comments_in_video_info)\n",
    "    return pd.DataFrame(all_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e124e8f-e404-41bf-ad84-cfb069b1c68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fascinating! Your background seems familiar to me. I have a bachelor degree in economic psychology, therefore learned a lot about social science methods mainly with SPSS. During my study i had also real quantitative research projects and I did my internship in an innovation research institute. After that i was for a short time a research employee. In this time i was able to boost my skills in SPSS, Excel and data science/analysis in general. Then i¬¥ve started to learn R. Currently i¬¥m working in data management but would like to move more towards data analysis/sciences. But for this i must improve my programming skills and i need more practial experience.',\n",
       " 'How much is required to become a job ready data scientist',\n",
       " \"When I was applying for Data Analytics job I sucked with numerical reasoning test, didn't even reach the SQL or Python skills testing part :)\",\n",
       " 'Thanks üôèüèºü§ç',\n",
       " 'Thank you so much for making these videos apart from your work life..  ‚ù§Ô∏è',\n",
       " 'I smushed the LIKE button.  Thank, Vu!',\n",
       " \"Miss Thu, kindly help me. I am 42 years old. I have an MBA degree and experience in admin/management. I enrolled in Master of Computer Science because of high demand in tech but in my university at master's level they didn't really help with any technical stuff and coding as they assumed everything we know from bachelors. So now I dropped out as I felt the time was being wasted by learning quantum computing to cloud to what not. Since I invested so much time in computer science, I want to specialize in data analytics, so I enrolled in Google certificate. I have taken 6 months off. I will be at home just studying and improving my skills. So, what do you recommend how i can make the most of these 6 months. I plan to finish Google certification in the next 2 months, then what do you suggest me and to enter data analytics job at 42, what should I prepare. Please help me sketch a roadmap. Pretty please. Thanks. I want to be very skilled by June\",\n",
       " 'Well done!',\n",
       " 'I like This content',\n",
       " 'Thank you for extremly useful knowledge, im very appreciated üéâ',\n",
       " \"Off topic, but I'd watch a channel where you softly read stories. You have a very friendly voice.\",\n",
       " \"As a tech manager and former engineer, I'm always on the lookout for ways to up my data science skills. Thanks for sharing these courses - they definitely look like some great options for anyone looking to learn fast. I'll definitely have to check them out. Thanks for the recommendation!\",\n",
       " 'I disagree , the reality is total different, the companies are asking all and I repeat ALL you have learnt after your training, as entry-level. No one is hiring just with basic skills. They Want Python, SQL, Advanced Excell, Numpy, Pandas, Power BI, probability and Statistic. I don`t know how you did, but with BSc and MSc in mathematics plus MSc in Project Management plus I start another Master in Data analytics and I can`t get any entry level in Data.',\n",
       " 'Hi Thu Vu!! in your opinion, how important is to get a certificate in order to prove that you know a tool (SQL, excel, tableau, etc). Because there are many free tutorials in youtube that you can learn from, but these dont give a certificate. \\nPlease  i want to master these tools but i dont know where to learn them, on payment platforms that come with certificates like COURSERA or on free platforms like YouTube but without a certificate...',\n",
       " 'ch·ªã ng∆∞·ªùi vi·ªát √† ch·ªã',\n",
       " \"What would be your recommendation to a 15-year-old girl who is interested or have a good predisposition to become a Data Scientist? How to maintain motivation by gradually acquiring the necessary knowledge to build DS solid foundation for students who do not have yet sufficient knowledge in math or sufficient research skills? Can students skip Excel, SQL... and jump into Jupyter and Pandas directly or is it best to start by learning the Python programming first, is there any Kaggle suitable for 15 year olds? How to maintain motivation for long time and don't give up too early on the path, which is full of challenges? Thank you, I like your channel a lot!\",\n",
       " 'Thx, Thu. Great informative content!',\n",
       " \"I can't believe how a person can explain all things related to Data science so beautifully. You are Awesome Thu vu....\",\n",
       " 'Thu Vu, I am reviewing from different universities in the USA. so, I am reviewing your data science from you too. I live in Paterson, NJ, USA. Bye.',\n",
       " 'How to join your online courses mam..is it free mam']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = get_comments_in_videos(youtube,video_ids)\n",
    "comments_df['comments'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85048325-175c-4053-b0f1-fd6baf5f1734",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80601c02-7857-4324-9059-54d2d70a50a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id         False\n",
       "channelTitle     False\n",
       "title            False\n",
       "description      False\n",
       "tags              True\n",
       "publishedAt      False\n",
       "viewCount        False\n",
       "likeCount        False\n",
       "favoriteCount    False\n",
       "commentCount     False\n",
       "duration         False\n",
       "definition       False\n",
       "caption          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vedio_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64bf7517-576c-43fa-a455-1df1cdcf9995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id         object\n",
       "channelTitle     object\n",
       "title            object\n",
       "description      object\n",
       "tags             object\n",
       "publishedAt      object\n",
       "viewCount        object\n",
       "likeCount        object\n",
       "favoriteCount    object\n",
       "commentCount     object\n",
       "duration         object\n",
       "definition       object\n",
       "caption          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vedio_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f6758dc-f7ea-413e-bebe-2995834df93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols=['viewCount','likeCount','favoriteCount','commentCount']\n",
    "vedio_df[numeric_cols]=vedio_df[numeric_cols].apply(pd.to_numeric,errors='coerce',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "364e70c7-f5ea-466d-b12a-57508463dc97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parser\n\u001b[0;32m      2\u001b[0m vedio_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublishedAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mvedio_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublishedAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:parser\u001b[38;5;241m.\u001b[39mparser(x))\n\u001b[0;32m      3\u001b[0m vedio_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublishedDayName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mvedio_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublishedAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'parse'"
     ]
    }
   ],
   "source": [
    "from parse import parser\n",
    "vedio_df['publishedAt']=vedio_df['publishedAt'].apply(lambda x:parser.parser(x))\n",
    "vedio_df['publishedDayName']=vedio_df['publishedAt'].apply(lambda x: x.strftime(\"%A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe7640-be54-48b8-9ee8-c23145f8a0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976ae29-1edc-43b9-9f18-518d2591ee93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
